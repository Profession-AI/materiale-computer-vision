{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMXDuSN9AUk/6M55gGthksh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **VGG16 & Imagenette**"],"metadata":{"id":"8qBZCzQIa8ho"}},{"cell_type":"code","source":["import torch.optim as optim\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as T\n","from torch.utils.data import DataLoader\n","import torch\n","import random\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import torch.nn.functional as F\n","import torchvision\n","from torch.utils.data import Dataset\n","import os\n","from PIL import Image\n","import torchvision.transforms as T"],"metadata":{"id":"lRiYcznqrYB2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Imagenette**\n","- 13394 RGB images\n","- 10 classi"],"metadata":{"id":"kaSbjX0pe-Ua"}},{"cell_type":"code","source":["_ = torchvision.datasets.Imagenette(\n","    root='./data',\n","    split=\"train\",\n","    # download=True,\n",")\n","\n","LABELS_MAP = {\n","    \"n01440764\": \"fish\",\n","    \"n02102040\": \"dog\",\n","    \"n02979186\": \"speaker\",\n","    \"n03000684\": \"electric saw\",\n","    \"n03028079\": \"church\",\n","    \"n03394916\": \"trumpet\",\n","    \"n03417042\": \"truck\",\n","    \"n03425413\": \"gas pump\",\n","    \"n03445777\": \"golf ball\",\n","    \"n03888257\": \"parachute\"\n","}\n","\n","label2target = {\n","    label: idx for idx, label in enumerate(LABELS_MAP.keys())\n","}"],"metadata":{"id":"At0BrDPudR8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ImageFolderDataset(Dataset):\n","\n","  def __init__(\n","      self,\n","      root_dir: str, # \"./data/imagenette2\"\n","      split: str = \"train\",\n","      labels_map: dict = LABELS_MAP,\n","      transform: callable = None\n","  ) -> None:\n","\n","    self.split_dir = os.path.join(root_dir, split) # e.g. \"./data/imagenette2/train\"\n","\n","    # mi serve perchè ad ogni label deve essere associato un numero\n","    # e.g. { \"n01440764\": 0, \"n02102040\": 1}\n","    label2target = {\n","        label: idx for idx, label in enumerate(labels_map.keys())\n","    }\n","\n","    self.images = []\n","    self.targets = []\n","    self.labels = []\n","    for class_id in os.listdir(self.split_dir):\n","      class_dir_path = os.path.join(self.split_dir, class_id)\n","      images = os.listdir(class_dir_path)\n","      self.images += [\n","          os.path.join(class_dir_path, image) for image in images\n","      ]\n","      self.targets += [label2target[class_id]]*len(images)\n","\n","      self.labels += [labels_map[class_id]]*len(images)\n","\n","    self.transform = transform\n","\n","\n","  def __getitem__(self, index):\n","\n","    image_path = self.images[index]\n","    image_target = self.targets[index]\n","    image_label = self.labels[index]\n","\n","    image = Image.open(image_path).convert('RGB')\n","    if self.transform:\n","      image = self.transform(image)\n","\n","    return image, image_target\n","\n","  def __len__(self):\n","    return len(self.images)\n"],"metadata":{"id":"KVHusU8a7GM9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_transform = T.Compose([\n","    T.Resize((224, 224)), # image size di VGG\n","    T.RandomApply([\n","      T.GaussianBlur(3, (0.5, 5)),\n","      T.ColorJitter(0.5, 0.1, 0.5, 0.1),\n","    ], p=.5),\n","    T.RandomHorizontalFlip(p=0.5),\n","    T.ToTensor(),\n","    # T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transform = T.Compose([\n","    T.Resize((224, 224)), # image size di VGG\n","    T.ToTensor(),\n","    # T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","batch_size = 64\n"],"metadata":{"id":"yoF-vOUxrubQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = ImageFolderDataset(\n","    root_dir=\"./data/imagenette2\",\n","    split=\"train\",\n","    transform=train_transform\n",")\n","\n","val_dataset = ImageFolderDataset(\n","    root_dir=\"./data/imagenette2\",\n","    split=\"val\",\n","    transform=val_transform\n",")\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"hQGm-2Qxr7zS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **VGG16 from scratch**"],"metadata":{"id":"VDSqm_69e8Jr"}},{"cell_type":"code","source":["class VGG16(nn.Module):\n","    def __init__(self, num_classes):\n","        super(VGG16, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU()\n","        )\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU()\n","        )\n","        self.layer4 = nn.Sequential(\n","            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","        self.layer5 = nn.Sequential(\n","            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU()\n","        )\n","        self.layer6 = nn.Sequential(\n","            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU()\n","        )\n","        self.layer7 = nn.Sequential(\n","            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","        self.layer8 = nn.Sequential(\n","            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU()\n","        )\n","        self.layer9 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU()\n","        )\n","        self.layer10 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","        self.layer11 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU()\n","        )\n","        self.layer12 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU()\n","        )\n","        self.layer13 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","        # modifica per far andare più veloce\n","        self.fc = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(7*7*512, 4096), # (7*7*512, 4096)\n","            nn.ReLU()\n","        )\n","\n","        self.fc1 = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096), # (4096, 4096)\n","            nn.ReLU()\n","        )\n","        self.fc2= nn.Sequential(\n","            nn.Linear(4096, num_classes) # (4096, num_classe)\n","        )\n","\n","        self.flatten = nn.Flatten()\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer5(x)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = self.layer8(x)\n","        x = self.layer9(x)\n","        x = self.layer10(x)\n","        x = self.layer11(x)\n","        x = self.layer12(x)\n","        x = self.layer13(x)\n","        x = self.flatten(x)\n","        x = self.fc(x)\n","        x = self.fc1(x)\n","        logits = self.fc2(x)\n","        return logits"],"metadata":{"id":"5BNazyN0yCo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = VGG16(num_classes=100)\n","# check if everythig is fine\n","x = torch.rand((2, 3, 96, 96))\n","logits = model(x)\n","print(logits.shape)"],"metadata":{"id":"cOiYBQvWrpnW","executionInfo":{"status":"ok","timestamp":1715504655490,"user_tz":-120,"elapsed":526,"user":{"displayName":"Riccardo Musmeci","userId":"06138046899083233740"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"050dae7b-6041-4d87-eb9d-4438167eab9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 100])\n"]}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001)\n","device = \"cpu\"\n","model.to(device);"],"metadata":{"id":"KCtpE2LARU95"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the neural network\n","num_epochs = 5\n","log_every_n_iter = 100\n","for epoch in range(num_epochs):\n","  # train loop\n","  model.train()\n","  epoch_loss = 0.0\n","  print(f\"Epoch: {epoch}\")\n","  for i, batch in enumerate(train_loader, 0):\n","    # batch --> (images, targets)\n","    x, targets, _, _ = batch\n","    x = x.to(device)\n","    targets = targets.to(device)\n","    # set optimizer a zero\n","    optimizer.zero_grad()\n","    # forward pass\n","    logits = model(x)\n","    # calcolo della loss\n","    loss = criterion(logits, targets)\n","    # backward pass\n","    loss.backward()\n","    # optimizer step --> update weights\n","    optimizer.step()\n","    epoch_loss += loss.item()\n","    if (i+1) % log_every_n_iter == 0:    # Print every log_every_n_iter mini-batches\n","        print(f\"> iter [{i+1}/{len(train_loader)}] - train_loss={epoch_loss/log_every_n_iter:.4f}\")\n","        epoch_loss = 0.0\n","    # test loop\n","  model.eval()\n","  val_loss = []\n","  total, correct = 0, 0\n","  with torch.no_grad():\n","    for batch in val_loader:\n","      x, targets, _, _ = batch\n","      x = x.to(device)\n","      targets = targets.to(device)\n","      logits = model(x)\n","      loss = criterion(logits, targets)\n","      val_loss.append(loss.item())\n","      # ottengo gli indici dove trovo la max probabilità\n","      _, preds = torch.max(logits.data, 1)\n","      total += targets.size(0)\n","      correct += (preds == targets).sum().item()\n","\n","  print(\"val report:\")\n","  print(f\"\\t val_loss={sum(val_loss)/len(val_loss):.4f} - val_accuracy={correct/total:.4f}\")\n","\n","  print(\" \\n *************** \\n\")\n","\n","print('Finished Training')"],"metadata":{"id":"fmEcBvB1z2Pn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Inference"],"metadata":{"id":"m9_YhT0CKl2U"}},{"cell_type":"code","source":["idx = random.randint(0, len(val_dataset))\n","img, target = val_dataset[idx]\n","image_path = val_dataset.images[idx]\n","label = val_dataset.labels[idx]\n","print(img.shape)\n","# we need to augment the first dimension --> from (C, H, W) -> (B, C, H, W)\n","x = img.unsqueeze(0)\n","print(x.shape)"],"metadata":{"id":"KQBSiVbZ0RI-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","with torch.no_grad():\n","  model.eval()\n","  logits = model(x.to(device))\n","  probs = F.softmax(logits, 1)\n","  print(probs.data)\n","  pred_prob, pred_class= torch.max(probs.data, 1)\n","  print(pred_class, pred_prob)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_WlE0moRIuYs","executionInfo":{"status":"ok","timestamp":1715441574172,"user_tz":-120,"elapsed":346,"user":{"displayName":"Riccardo Musmeci","userId":"06138046899083233740"}},"outputId":"324d14a0-eaac-438e-c849-426299832e0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3.0209e-05, 9.6808e-01, 2.5137e-03, 6.9704e-03, 8.4398e-04, 1.5312e-03,\n","         1.1032e-03, 1.0808e-02, 3.0216e-03, 5.0998e-03]], device='cuda:0')\n","tensor([1], device='cuda:0') tensor([0.9681], device='cuda:0')\n"]}]},{"cell_type":"code","source":["image = Image.open(image_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXLynpp3LIVz","executionInfo":{"status":"ok","timestamp":1715441590858,"user_tz":-120,"elapsed":278,"user":{"displayName":"Riccardo Musmeci","userId":"06138046899083233740"}},"outputId":"e06f7c2c-2de0-4bc6-dcbc-e698c4dd62d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(28, 28, 1)\n"]}]},{"cell_type":"code","source":["pred_label_key = list(LABELS_MAP)[pred_class[0]]\n","pred_label_name = LABELS_MAP[pred_label_key]\n","\n","print(f\"Predicted class is {pred_label_name} with prob={pred_prob[0]:.4f} - Ground Truth class is {gt_label}\")\n","plt.imshow(image)"],"metadata":{"id":"5ENi-8LOMIyZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZioPu6fvMl3j"},"execution_count":null,"outputs":[]}]}